{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14c3f35",
   "metadata": {},
   "source": [
    "# Preprocesado de datasets\n",
    "En este cuaderno, se pasan los distintos dataset para corregirlos al formato correcto. Las imágenes que entran al modelo, deben en formato PNG, por lo que las imágenes de radiografia se convierten a png y si tienen mascara, esta se convierte a png con pixeles con valor 0 o 1, fondo y vertebra respectivamente.\n",
    "Ademas estas imagenes se organizan en distintas carpetas... no se si especificar las carpetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c71818-1cfd-4a5c-8631-88a558571447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install segmentation-models-pytorch\n",
    "#!pip install pytorch-lightning\n",
    "#!pip install matplotlib\n",
    "#!pip install opencv-python\n",
    "#!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c03fdd0a-085e-4f47-8561-40173a65cd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tania\\miniconda3\\envs\\tf_gpu\\lib\\site-packages\\albumentations\\__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.5' (you have '2.0.3'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from pprint import pprint\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import albumentations as alb \n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import random\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e8c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_original = 'dataset_original' # Carpeta donde se encuentran las imagenes originales\n",
    "ruta_procesado = 'dataset_procesado' # Carpeta donde se guardaran las imagenes procesadas\n",
    "\n",
    "con_mascara = 'dataset_con_mascara' # Carpeta donde se encuentran las imagenes con mascara\n",
    "sin_mascara = 'dataset_sin_mascara' # Carpeta donde se encuentran las imagenes sin mascara\n",
    "\n",
    "imagenes = 'imagenes'\n",
    "mascaras = 'mascaras'\n",
    "\n",
    "cervical = 'cervical'\n",
    "lumbar = 'lumbar'\n",
    "columna = 'columna_completa'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d83fc4",
   "metadata": {},
   "source": [
    "## Preprocesado del dataset NHANES II\n",
    "Las imagenes de radiografias se convierten de pkl a png.\n",
    "\n",
    "Las mascaras tambien se pasan a png pero, los pixeles toman valor binario:\n",
    "  - 0: fondo\n",
    "  - 1: vértebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20042e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pkl_2_png_con_mascara(ruta_entrada, ruta_salida):\n",
    "  cervical_img = os.path.join(ruta_salida, 'cervical', imagenes)\n",
    "  cervical_masc = os.path.join(ruta_salida, 'cervical', mascaras)\n",
    "  lumbar_img = os.path.join(ruta_salida, 'lumbar', imagenes)\n",
    "  lumbar_masc = os.path.join(ruta_salida, 'lumbar', mascaras)\n",
    "\n",
    "  rutas_salida = [cervical_img, cervical_masc, lumbar_img, lumbar_masc] \n",
    "\n",
    "  for ruta in rutas_salida:\n",
    "    if not os.path.exists(ruta):\n",
    "      os.makedirs(ruta)\n",
    "  \n",
    "  for nombre_fichero in os.listdir(ruta_entrada):\n",
    "    if nombre_fichero.endswith('.pkl'):\n",
    "      ruta_imagen = ''\n",
    "      ruta_mascara = ''\n",
    "      if 'cervical' in nombre_fichero.lower().split('_'):\n",
    "        ruta_imagen = cervical_img\n",
    "        ruta_mascara = cervical_masc\n",
    "      else:\n",
    "        ruta_imagen = lumbar_img\n",
    "        ruta_mascara = lumbar_masc\n",
    "\n",
    "      ruta_fichero = os.path.join(ruta_entrada, nombre_fichero)\n",
    "\n",
    "      with open(ruta_fichero, 'rb') as fichero:\n",
    "        dato = pkl.load(fichero)\n",
    "\n",
    "      imagen = dato['image']\n",
    "      mascara = dato['masks']['vertebrae']\n",
    "\n",
    "      # Guardamos la imagen\n",
    "      png_imagen = Image.fromarray(imagen)\n",
    "      ruta_png_imagen = os.path.join(ruta_imagen, nombre_fichero.replace('_masks_4.pkl', '.png'))\n",
    "      png_imagen.save(ruta_png_imagen)\n",
    "\n",
    "      # Guardamos la máscara binaria\n",
    "      png_mascara = Image.fromarray((mascara).astype(np.uint8)) # Convertimos a uint8 para que se guarde correctamente\n",
    "      ruta_png_mascara = os.path.join(ruta_mascara, nombre_fichero.replace('_masks_4.pkl', '.png'))\n",
    "      png_mascara.save(ruta_png_mascara)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbdd0483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de los datos originales\n",
    "dataset = 'NHANESII_Annotations_VertebralOsetophytes/nhanes'\n",
    "ruta_entrada = os.path.join(ruta_original, dataset)\n",
    "\n",
    "# Rutas de salida de las imágenes y máscaras\n",
    "ruta_salida = os.path.join(ruta_procesado, con_mascara)\n",
    "\n",
    "# Convertimos los ficheros pkl a png\n",
    "pkl_2_png_con_mascara(ruta_entrada, ruta_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e607d16",
   "metadata": {},
   "source": [
    "## Preprocesado de dataset Rxs\n",
    "En este caso, solo se dispone de imagenes de radiografias jpg sin mascara, estas se usaran solo para obtener las predicciones.\n",
    "El preprocesado que se debe realizar es, cambiar su formato a png y redimencionar las imagenes para que sean multiplos de 32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c84732c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jpg_2_png(ruta_entrada, ruta_salida, es_gris=True):\n",
    "  if not os.path.exists(ruta_salida):\n",
    "    os.makedirs(ruta_salida)\n",
    "\n",
    "  for nombre_fichero in os.listdir(ruta_entrada):\n",
    "    if nombre_fichero.endswith('.jpg'):\n",
    "      ruta_fichero = os.path.join(ruta_entrada, nombre_fichero)\n",
    "      \n",
    "      if es_gris:\n",
    "        imagen = cv2.imread(ruta_fichero, cv2.IMREAD_GRAYSCALE)\n",
    "      else:\n",
    "        pil_imagen = Image.open(ruta_fichero).convert('L') # Convertimos a escala de grises\n",
    "        imagen = np.array(pil_imagen).astype(np.uint8)\n",
    "        imagen = cv2.cvtColor(imagen, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "      if imagen is not None:\n",
    "        png_imagen = Image.fromarray(imagen)\n",
    "        ruta_imagen = os.path.join(ruta_salida, nombre_fichero.replace('.jpg', '.png'))\n",
    "        png_imagen.save(ruta_imagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c2e5b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Rxs'\n",
    "ruta_entrada_lumbar = os.path.join(ruta_original, dataset, lumbar)\n",
    "ruta_salida_lumbar = os.path.join(ruta_procesado, sin_mascara, lumbar, imagenes)\n",
    "jpg_2_png(ruta_entrada_lumbar, ruta_salida_lumbar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5518d179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [2 2 2]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n",
      "<PIL.Image.Image image mode=RGB size=2844x6235 at 0x1ADBF5BC4C0>\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [2 2 2]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n",
      "<PIL.Image.Image image mode=RGB size=2844x6235 at 0x1ADBB40BCD0>\n",
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [1 1 1]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [2 2 2]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n",
      "<PIL.Image.Image image mode=RGB size=2844x6235 at 0x1ADBF5BC4C0>\n"
     ]
    }
   ],
   "source": [
    "# Ruta de los datos originales\n",
    "dataset = 'Rxs'\n",
    "ruta_entrada_cervical = os.path.join(ruta_original, dataset, cervical)\n",
    "ruta_entrada_lumbar = os.path.join(ruta_original, dataset, lumbar)\n",
    "ruta_entrada_columna = os.path.join(ruta_original, dataset, columna)\n",
    "\n",
    "# Rutas de salida de las imágenes y máscaras\n",
    "ruta_salida_cervical = os.path.join(ruta_procesado, sin_mascara, cervical, imagenes)\n",
    "ruta_salida_lumbar = os.path.join(ruta_procesado, sin_mascara, lumbar, imagenes)\n",
    "ruta_salida_columna = os.path.join(ruta_procesado, sin_mascara, columna, imagenes)\n",
    "\n",
    "# Convertimos los ficheros jpg a png\n",
    "jpg_2_png(ruta_entrada_cervical, ruta_salida_cervical)\n",
    "jpg_2_png(ruta_entrada_lumbar, ruta_salida_lumbar)\n",
    "jpg_2_png(ruta_entrada_columna, ruta_salida_columna, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
